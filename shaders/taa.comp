#version 460
#extension GL_EXT_samplerless_texture_functions : require
#extension GL_GOOGLE_include_directive : enable

#include "shader_cpu_common.h"

// NOTE: This shader is totally NOT optimized for performance, but instead designed to experimant with different settings!

// ATTENTION:
// with upsampling enabled, the texture sizes are different:
// lo-res: uCurrentFrame, uCurrentDepth, uCurrentVelocity, *uHistoryDepth*
// hi-res: uHistoryFrame, uResult, uDebug
//
// FIXME: decide res for uHistoryDepth (?)
// FIXME: hist depth sampling is problematic

// TODO upsampling:
// unjittering ?


// NOTE: if tonemapping is used: history buffer always contains tonemapped samples

// ###### SRC/DST IMAGES #################################
layout(set = 0, binding = 0) uniform sampler uSampler;
layout(set = 0, binding = 1) uniform texture2D uCurrentFrame;
layout(set = 0, binding = 2) uniform texture2D uCurrentDepth;
layout(set = 0, binding = 7) uniform texture2D uCurrentVelocity;
layout(set = 0, binding = 3) uniform texture2D uHistoryFrame;
layout(set = 0, binding = 4) uniform texture2D uHistoryDepth;
layout(set = 0, binding = 5, TAA_SHADER_OUTPUT_FORMAT) writeonly uniform restrict image2D uResultScreen;
layout(set = 0, binding = 8, TAA_SHADER_OUTPUT_FORMAT) writeonly uniform restrict image2D uResultHistory;
layout(set = 0, binding = 6, rgba16f) writeonly uniform restrict image2D uDebug;
// -------------------------------------------------------

// texelFetch is undefined when sampling outside the texture, so always clamp
#define CLAMP_TO_TEX(v) clamp((v), ivec2(0), textureSize(uCurrentFrame,0))

// shortcut to texture(sampler2D(texture, uSampler), uv)
#define SAMPLE_TEX(tex_,uv_) texture(sampler2D((tex_),uSampler), uv_)

#define JITTER_UV (ubo.mJitterNdc.xy * 0.5 * params.mUnjitterFactor)

// ###### PUSH CONSTANTS AND UBOs ########################
struct Parameters {
	float mAlpha;
	int  mColorClampingOrClipping;
	bool mDepthCulling;
	bool mUnjitterNeighbourhood;
	bool mUnjitterCurrentSample;	// TODO: anything for depth/history depth??
	float mUnjitterFactor;			// -1 or +1, for debugging
	bool mPassThrough;				// effectively disables TAA: history <- input, result <- input,
	bool mUseYCoCg;
	bool mShrinkChromaAxis;			// ony used if mUseYCoCg - reduce Chroma influence on clip box
	bool mVarianceClipping;
	bool mShapedNeighbourhood;
	bool mLumaWeightingLottes;
	float mVarClipGamma;
	float mMinAlpha;				// used for luminance-based weighting (Lottes)
	float mMaxAlpha;				// used for luminance-based weighting (Lottes)
	float mRejectionAlpha;
	bool mRejectOutside;
	int mUseVelocityVectors;		// 0=off 1=for movers only 2=for everything
	int mVelocitySampleMode;		// 0=simple 1=3x3_max 2=3x3_closest
	int mInterpolationMode;			// 0=bilinear 1=bicubic b-spline 2=bicubic catmull-rom
	bool mToneMapLumaKaris;			// "tone mapping" by luma weighting (Karis)
	bool mAddNoise;
	float mNoiseFactor;				// small, way less than 1, e.g. 1/512
	bool mReduceBlendNearClamp;		// reduce blend factor when near clamping (Karis14)

	vec4 mDebugMask;
	int  mDebugMode;
	float mDebugScale;
	bool mDebugCenter;

	float pad1;
};

//layout(push_constant) uniform PushConstants {
//} pushConstants;

Parameters params;

layout(set = 1, binding = 0) uniform Matrices {
	mat4 mHistoryViewProjMatrix;
	mat4 mInverseViewProjMatrix;

	Parameters	param[2];
	vec4        mJitterNdc;		// only .xy used; jitter is in NDC units, NOT UV units!
	vec4		mSinTime;		// sin(t/8), sin(t/4), sin(t/2), sin(t)
	bool		splitScreen;
	int			splitX;
	bool        mUpsampling;

	bool        mBypassHistoryUpdate;
	bool        mResetHistory;

	float pad1,pad2,pad3;
} ubo;
// -------------------------------------------------------

// Globals
ivec2 textureSize_loRes;
ivec2 textureSize_hiRes;

// Just for debugging:
vec4 gDebugValue = vec4(0);

// ###### HELPER FUNCTIONS ###############################

// texel coords <-> uv conversion
vec2  tc_to_uv(ivec2 tc, ivec2 texSize) { return (vec2(tc) + 0.5) / texSize; }
ivec2 uv_to_tc(vec2 uv,  ivec2 texSize) { return ivec2(uv * texSize); }

ivec2 hiRes_to_loRes_Tc(ivec2 hires_tc) {
	return uv_to_tc(tc_to_uv(hires_tc, textureSize_hiRes), textureSize_loRes);
}


//// convert from RGB to YCoCg-R ; see https://en.wikipedia.org/wiki/YCoCg
//vec3 rgb_to_ycocg(vec3 c) {
//	float co  = c.r - c.b;
//	float tmp = c.b + co * .5;
//	float cg  = c.g - tmp;
//	float y   = tmp + cg * .5;
//	return vec3(y,co,cg);
//}
//
//// convert from YCoCg-R to RGB
//vec3 ycocg_to_rgb(vec3 c) {
//	float tmp = c.x - c.z * .5;
//	float g   = c.z + tmp;
//	float b   = tmp - c.y * .5;
//	float r   = b + c.y;
//	return vec3(r,g,b);
//}

// convert from RGB to YCoCg ; see https://en.wikipedia.org/wiki/YCoCg
vec3 rgb_to_ycocg(vec3 c) {
	return vec3(
		 .25 * c.r + .5 * c.g + .25 * c.b,
		 .5  * c.r            - .5  * c.b,
		-.25 * c.r + .5 * c.g - .25 * c.b
	);
}

// convert from YCoCg to RGB
vec3 ycocg_to_rgb(vec3 c) {
	float tmp = c.x - c.z;	// tmp = Y   - Cg;
	return vec3(
		tmp + c.y,	// R   = tmp + Co;
		c.x + c.z,	// G   = Y   + Cg;
		tmp - c.y	// B   = tmp - Co;
	);
}


vec3 maybe_rgb_to_ycocg(vec3 c) { return params.mUseYCoCg ? rgb_to_ycocg(c) : c; }
vec3 maybe_ycocg_to_rgb(vec3 c) { return params.mUseYCoCg ? ycocg_to_rgb(c) : c; }
float luminance(vec3 c) { return params.mUseYCoCg ? c.x : rgb_to_ycocg(c).x; }

// luma-weighted "tone mapping" (Karis); see http://graphicrants.blogspot.com/2013/12/tone-mapping.html
vec3 tonemap_rgb(vec3 hdr) {
	if (params.mToneMapLumaKaris) {
		float luma = max(max(hdr.r, hdr.g), hdr.b);
		return hdr / (1.0 + luma);
	} else {
		return hdr;
	}
}
vec3 un_tonemap_rgb(vec3 ldr) {
	if (params.mToneMapLumaKaris) {
		float luma = max(max(ldr.r, ldr.g), ldr.b);
		return ldr / (1.0 - luma);
	} else {
		return ldr;
	}
}

void getNeighbourhood(in ivec2 iuv, out vec3 cC, out vec3 c1, out vec3 c2, out vec3 c3, out vec3 c4, out vec3 c5, out vec3 c6, out vec3 c7, out vec3 c8) {
	vec2 offset = params.mUnjitterNeighbourhood ? JITTER_UV : vec2(0);

	vec2 invsize = vec2(1) / textureSize(uCurrentFrame, 0);

	cC = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv                 + 0.5) * invsize).rgb));
	c1 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2(-1, -1) + 0.5) * invsize).rgb));
	c2 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 0, -1) + 0.5) * invsize).rgb));
	c3 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 1, -1) + 0.5) * invsize).rgb));
	c4 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2(-1,  0) + 0.5) * invsize).rgb));
	c5 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 1,  0) + 0.5) * invsize).rgb));
	c6 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2(-1,  1) + 0.5) * invsize).rgb));
	c7 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 0,  1) + 0.5) * invsize).rgb));
	c8 = maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 1,  1) + 0.5) * invsize).rgb));
}

// may have different unjitter settings than getNeighbourhood
vec3 getCurrentColor(in ivec2 iuv) {
	vec2 offset = params.mUnjitterCurrentSample ? JITTER_UV : vec2(0);
	vec2 invsize = vec2(1) / textureSize(uCurrentFrame, 0);
	return maybe_rgb_to_ycocg(tonemap_rgb(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + 0.5) * invsize).rgb));
}

vec3 getCurrentUpsampledColor(in ivec2 currentTc, in vec2 currentUv, out float beta) {
	// non-upsampling behaviour was:
	//beta = 1.0; return getCurrentColor(hiRes_to_loRes_Tc(currentTc));

	// only consider input samples that fall into the current texel after upscaling

	// example: hi-res = 2 x lores, consider input at center of texels 100, 101 -> = tc 100.5 (with non-normalized texture-coords tc); jitter is in texel units
	// jitter 0   : input 100.50 -> output 201.0 (203.0)
	// jitter -.25: input 100.25 -> output 200.5 (202.5)
	// jitter +.25: input 100.75 -> output 201.5 (203.5)
	// jitter -.40: input 100.10 -> output 200.2 (202.2), so update output tc [200-201) and [202-203), but not [201-202)
	// jitter J   : input I+J    -> output scale * (I + J)
	// O = s * (I + J) -> O/s - J = I

	vec2 scale = vec2(textureSize_hiRes) / vec2(textureSize_loRes);

	vec2 texelJitter = JITTER_UV * textureSize_loRes * -1;	// * -1 works... but WHY subtract jitter instead of adding?
	vec2 inTcSample;
	vec2 foundTc = vec2(-1,-1);
	const float almostOne = 0.999999;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(0,        0        )) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(almostOne,0        )) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(0,        almostOne)) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(almostOne,almostOne)) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;

	//gDebugValue = foundTc.x >= 0.0 ? vec4(1, foundTc, 0) : vec4(0);	

	if (foundTc.x >= 0.0) {
		beta = 1.0;
		vec2 texUv = (floor(foundTc) + 0.5) / textureSize_loRes;
		return maybe_rgb_to_ycocg(tonemap_rgb(SAMPLE_TEX(uCurrentFrame, texUv).rgb));
	} else {
		beta = 0.0;
		return vec3(0);
	}
}

void getColorAndAabb(in ivec2 iuv, out vec3 centerCol, out vec3 minCol, out vec3 maxCol, out vec3 cliptowardsCol)
{
	const float N = 9.0; // number of samples
	vec3 c1,c2,c3,c4,c5,c6,c7,c8;
	getNeighbourhood(iuv, centerCol,c1,c2,c3,c4,c5,c6,c7,c8);

	// variance clipping?
	if (params.mVarianceClipping) {
		vec3 m1 = centerCol + c1 + c2 + c3 + c4 + c5 + c6 + c7 + c8;
		vec3 m2 = centerCol*centerCol + c1*c1 + c2*c2 + c3*c3 + c4*c4 + c5*c5 + c6*c6 + c7*c7 + c8*c8;
		vec3 mean = m1 / N;
		vec3 sigma = sqrt(max(vec3(0), m2 / N - mean * mean));	// !! Here be dragons! (due to precision? - without the max(), some sigma components can get NaN!)
		minCol = mean - params.mVarClipGamma * sigma;
		maxCol = mean + params.mVarClipGamma * sigma;

		// NOTE: it is NOT guaranteed that centerCol is inside the AABB !
		// so clip towards the mean
		cliptowardsCol = mean;

		// TODO: we can even clip the other AABB against this one
	} else if (params.mShapedNeighbourhood) {
		vec3 minCol_3x3  = min(min(min(min(min(min(min(min(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		vec3 maxCol_3x3  = max(max(max(max(max(max(max(max(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		vec3 minCol_5tap = min(min(min(min(centerCol, c2), c4), c5), c7);
		vec3 maxCol_5tap = max(max(max(max(centerCol, c2), c4), c5), c7);
		minCol = (minCol_3x3 + minCol_5tap) * 0.5;
		maxCol = (maxCol_3x3 + maxCol_5tap) * 0.5;
		cliptowardsCol = centerCol;

	} else {
		minCol = min(min(min(min(min(min(min(min(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		maxCol = max(max(max(max(max(max(max(max(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		cliptowardsCol = centerCol; // here centerCol is always inside the AABB; note: playdead still clip towards average color 
	}

	if (params.mUseYCoCg && params.mShrinkChromaAxis) {
		// shrink clip-box in the two chroma axes (see Inside-code from playdead, and [Karis14])
		// .r = Y = luma, .gb = CoCg = Chroma (chroma orange, chroma green)
		// NOTE:
		// This is differen from "Inside".
		// "Inside" calcs chroma box size directly from Luma (.r) size, but that doesn't make any sense... does it?
		// And Inside sets box center to current texel color.

		//vec2 halfSize = 0.25 * 0.5 * vec2(maxCol.gb - minCol.gb);
		//vec2 center = centerCol.gb;
		//minCol.gb = center - halfSize;
		//maxCol.gb = center + halfSize;
		//cliptowardsCol.gb = center;

		const vec3 scaleYCoCg = vec3(1.0, 0.5, 0.5);
		vec3 halfSize = 0.5 * scaleYCoCg * (maxCol - minCol);
		vec3 center = (minCol + maxCol) * 0.5;
		minCol = center - halfSize;
		maxCol = center + halfSize;
		if (any(lessThan(cliptowardsCol, minCol)) || any(greaterThan(cliptowardsCol, maxCol))) cliptowardsCol = center;
	}

	// TODO: optionally unjitter differently: neighbourhood samples, current color -> need to make sure cliptowardsCol stays inside AABB

	//if (any(lessThan(centerCol, minCol)) || any(greaterThan(centerCol, maxCol))) gDebugValue = vec4(1,0,0,0);
}

// Code from Temporal Reprojection Anti-Aliasing in INSIDE: https://youtu.be/2XXS5UyNjjU?t=939
// note: clips towards aabb center + p.w
vec4 clipAabb(
	vec3 aabbMin, // cn_min
	vec3 aabbMax, // cn_max
	vec4 p,       // c_in'		// only p.w is used (and typically is 1)
	vec4 q)       // c_hist
{
	const float eps = 1e-7;

	vec3 pClip = 0.5 * (aabbMax + aabbMin);
	vec3 eClip = 0.5 * (aabbMax - aabbMin) + eps; // ac: added epsilon

	vec4 vClip = q - vec4(pClip, p.w);
	vec3 vUnit = vClip.xyz / eClip;
	vec3 aUnit = abs(vUnit);
	float maUnit = max(aUnit.x, max(aUnit.y, aUnit.z));

	if (maUnit > 1.0) {
		return vec4(pClip, p.w) + vClip / maUnit;
	}
	else {
		return q; // point inside aabb
	}
}

// slow clipping, but not only towards centre; code from playdead -- DOES NOT WORK PROPERLY!
vec4 clipAabbSlow(
	vec3 aabbMin, // cn_min
	vec3 aabbMax, // cn_max
	vec4 p,       // c_in'
	vec4 q)       // c_hist
{
		vec4 r = q - p;
		vec3 rmax = aabbMax - p.xyz;
		vec3 rmin = aabbMin - p.xyz;

		const float eps = 1e-7;

		// !! BEWARE !! divs by zero happen here !!
		if (r.x > rmax.x + eps) r *= (rmax.x / r.x);
		if (r.y > rmax.y + eps) r *= (rmax.y / r.y);
		if (r.z > rmax.z + eps) r *= (rmax.z / r.z);
		if (r.x < rmin.x - eps) r *= (rmin.x / r.x);
		if (r.y < rmin.y - eps) r *= (rmin.y / r.y);
		if (r.z < rmin.z - eps) r *= (rmin.z / r.z);

		return p + r;
}

vec3 findClosestUvAndZ_3x3(vec2 uv) {
	// uv should be dead-center on a texel, we don't want to interpolate the depth buffer!

	vec2 toUv = vec2(1,1) / textureSize(uCurrentDepth, 0);

	vec2 offset, closestOffset;
	float d, dClosest;
	offset = toUv * vec2(-1,-1); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r;                     closestOffset = offset; dClosest = d;
	offset = toUv * vec2( 0,-1); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }
	offset = toUv * vec2( 1,-1); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }
	offset = toUv * vec2(-1, 0); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }
	offset = toUv * vec2( 0, 0); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }
	offset = toUv * vec2( 1, 0); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }
	offset = toUv * vec2(-1, 1); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }
	offset = toUv * vec2( 0, 1); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }
	offset = toUv * vec2( 1, 1); d = SAMPLE_TEX(uCurrentDepth, uv + offset).r; if (d < dClosest) { closestOffset = offset; dClosest = d; }

	return vec3(uv + closestOffset, dClosest);
}

void getHistoryPosition(in vec2 currentUv, in float currentDepth, out vec2 historyUv, out float historyDepth) {
	vec4 velocitySample = SAMPLE_TEX(uCurrentVelocity, currentUv);

	bool canUseVelocity = true;
	if (params.mUseVelocityVectors == 0 || (params.mUseVelocityVectors == 1 && velocitySample.w < 0.5)) canUseVelocity = false;

	if (canUseVelocity) {
		if (params.mVelocitySampleMode == 1) {
			// 3x3 longest
			// sample 3x3 neighbourhood, take longest vector
			vec2 toUv = vec2(1,1) / textureSize(uCurrentVelocity, 0);
			vec2 maxVel = velocitySample.xy;
			vec2 sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 1, -1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2(-1,  0)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2(-1, -1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 0, -1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2(-1,  1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 0,  1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 1,  0)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 1,  1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			velocitySample.xy = sam;
		} else if (params.mVelocitySampleMode == 2) {
			// 3x3 closest
			// find closest fragment in 3x3 neighbourhood from depth buffer, sample velocity from that location
			vec3 closestUvAndZ = findClosestUvAndZ_3x3(currentUv);
			velocitySample = SAMPLE_TEX(uCurrentVelocity, closestUvAndZ.xy);
		} // else: we already have the simple velocity sample

		// velocity sample is already scaled from ndc to uv in .xy, .z holds the raw (ndc) depth difference
		historyUv    = currentUv    - velocitySample.xy;
		historyDepth = currentDepth - velocitySample.z;
		// TODO: check if material history is same object and set canUseVelocity = false otherwise
	}

	if (!canUseVelocity) {
		vec4 clipSpace = vec4(currentUv * 2.0 - 1.0, currentDepth, 1);
		vec4 worldSpace = ubo.mInverseViewProjMatrix * clipSpace;
		vec4 historyClipSpace = ubo.mHistoryViewProjMatrix * worldSpace;
		historyUv = (historyClipSpace.xy / historyClipSpace.w) * 0.5 + 0.5;
		historyDepth = historyClipSpace.z / historyClipSpace.w;
	}

	// TODO: need to adjust for current jitter if history buf is considered unjittered?
}

// see https://vec3.ca/bicubic-filtering-in-fewer-taps/
vec4 sample_history_bicubic_catmullrom(vec2 uv) {
	vec2 texSize = textureSize(uHistoryFrame, 0);
	vec2 invTexSize = 1.0 / texSize;

	vec2 iTc = uv * texSize;
	vec2 tc = floor(iTc - 0.5) + 0.5;	// round *down* to nearest texel center
	vec2 f = iTc - tc;
	vec2 f2 = f * f;
	vec2 f3 = f2 * f;

	// Calculate weights:
	//                   9|d|^3 - 15|d|^2         +  6   for 0 <= |d| <= 1
	// w(d) = (1/6) * { -3|d|^3 + 15|d|^2 - 24|d| + 12   for 1 <  |d| <= 2
	//                   0                               otherwise
	//
	// |d0|=f+1   |d1|=f   |d2|=1-f   |d3|=2-f
	//
	// expands to:
	//  w0 = (-3 * f^3 +  6 * f^2 - 3 * f     ) / 6
	//  w1 = ( 9 * f^3 - 15 * f^2         + 6 ) / 6	      ! there is a typo in the linked article! coefficient for f^3 is 9, not 6 !
	//  w2 = (-9 * f^3 + 12 * f^2 + 3 * f     ) / 6
	//  w3 = ( 3 * f^3 -  3 * f^2             ) / 6

	vec2 w0 = -0.5 * f3 +        f2 - 0.5 * f       ;
	vec2 w1 =  1.5 * f3 -  2.5 * f2           + 1.0 ;
	vec2 w2 = -1.5 * f3 +  2.0 * f2 + 0.5 * f       ;
	vec2 w3 =  0.5 * f3 -  0.5 * f2                 ;

	#if 0
		// naive implementation, slow (16 taps!), just for comparison

		// Note: there is *no* linear interpolation going on, we sample the texture at exact texel centers.
		//       Works equally well with texture() or texelFetch() (which needs manual clamping)
		//       Tests showed the texelFetch-variant is minusculely faster, but the difference is barely noticeable 
		ivec2 tc0 = clamp(ivec2(tc - 1), ivec2(0), ivec2(texSize));
		ivec2 tc1 = clamp(ivec2(tc 	  ), ivec2(0), ivec2(texSize));
		ivec2 tc2 = clamp(ivec2(tc + 1), ivec2(0), ivec2(texSize));
		ivec2 tc3 = clamp(ivec2(tc + 2), ivec2(0), ivec2(texSize));
		return
		  texelFetch(uHistoryFrame, ivec2(tc0.x, tc0.y), 0) * w0.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc0.y), 0) * w1.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc0.y), 0) * w2.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc0.y), 0) * w3.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc0.x, tc1.y), 0) * w0.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc1.y), 0) * w1.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc1.y), 0) * w2.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc1.y), 0) * w3.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc0.x, tc2.y), 0) * w0.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc2.y), 0) * w1.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc2.y), 0) * w2.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc2.y), 0) * w3.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc0.x, tc3.y), 0) * w0.x * w3.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc3.y), 0) * w1.x * w3.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc3.y), 0) * w2.x * w3.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc3.y), 0) * w3.x * w3.y;
	#else
		// optimized version, 9 taps only
		// Note: this exploits bilinear filtering, so no texelFetch'ing here!
		vec2 wC = w1 + w2;
		vec2 tc0 = (tc - 1    ) * invTexSize;
		vec2 tcC = (tc + w2/wC) * invTexSize;
		vec2 tc3 = (tc + 2    ) * invTexSize;
		return
		  SAMPLE_TEX(uHistoryFrame, vec2(tc0.x, tc0.y)) * w0.x * w0.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tcC.x, tc0.y)) * wC.x * w0.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc3.x, tc0.y)) * w3.x * w0.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc0.x, tcC.y)) * w0.x * wC.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tcC.x, tcC.y)) * wC.x * wC.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc3.x, tcC.y)) * w3.x * wC.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc0.x, tc3.y)) * w0.x * w3.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tcC.x, tc3.y)) * wC.x * w3.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc3.x, tc3.y)) * w3.x * w3.y;
	#endif
}

// see https://vec3.ca/bicubic-filtering-in-fewer-taps/
vec4 sample_history_bicubic_b_spline(vec2 uv) {
	vec2 texSize = textureSize(uHistoryFrame, 0);
	vec2 invTexSize = 1.0 / texSize;

	vec2 iTc = uv * texSize;
	vec2 tc = floor(iTc - 0.5) + 0.5;	// round *down* to nearest texel center
	vec2 f = iTc - tc;
	vec2 f2 = f * f;
	vec2 f3 = f2 * f;

	vec2 w0 = f2 - 0.5 * (f3 + f);
	vec2 w1 = 1.5 * f3 - 2.5 * f2 + 1.0;
	vec2 w3 = 0.5 * (f3 - f2);
	vec2 w2 = 1.0 - w0 - w1 - w3;

	vec2 s0 = w0 + w1;
	vec2 s1 = w2 + w3;
	vec2 f0 = w1 / (w0 + w1);
	vec2 f1 = w3 / (w2 + w3);
	vec2 t0 = (tc - 1 + f0) * invTexSize;
	vec2 t1 = (tc + 1 + f1) * invTexSize;

	return (SAMPLE_TEX(uHistoryFrame, vec2(t0.x, t0.y)) * s0.x
	     +  SAMPLE_TEX(uHistoryFrame, vec2(t1.x, t0.y)) * s1.x) * s0.y
	     + (SAMPLE_TEX(uHistoryFrame, vec2(t0.x, t1.y)) * s0.x
	     +  SAMPLE_TEX(uHistoryFrame, vec2(t1.x, t1.y)) * s1.x) * s1.y;
}

vec4 sample_history_rgb(vec2 uv) {
	if      (params.mInterpolationMode == 0)	return SAMPLE_TEX(uHistoryFrame, uv);
	else if (params.mInterpolationMode == 1)	return sample_history_bicubic_b_spline(uv);
	else										return sample_history_bicubic_catmullrom(uv);
}

vec4 noise(vec2 uv) {
	vec2 seed = uv + ubo.mSinTime.x + 0.6959174;
	vec4 nRand = fract( sin(dot(seed, vec2(12.9898, 78.233))) * vec4(43758.5453, 28001.8384, 50849.4141, 12996.89) ); // normalized [0,1)
	vec4 sRand = nRand * 2.0 - 1.0; // [-1,1)
	return sRand * params.mNoiseFactor;
}

// -------------------------------------------------------

// ################## COMPUTE SHADER MAIN ###################
layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;
void main()
{
	textureSize_hiRes = textureSize(uHistoryFrame, 0);
	textureSize_loRes = textureSize(uCurrentFrame, 0);

	ivec2 iuv = ivec2(gl_GlobalInvocationID.xy);
	vec2 uv = tc_to_uv(iuv, textureSize_hiRes);
	if (any(greaterThanEqual(iuv, textureSize_hiRes))) return;

	int paramsIdx = (ubo.splitScreen && iuv.x > ubo.splitX) ? 1 : 0;
	params = ubo.param[paramsIdx];


	ivec2 iuv_lores = uv_to_tc(uv, textureSize_loRes);

	if (params.mPassThrough) {
		imageStore(uResultScreen,  iuv, vec4(texelFetch(uCurrentFrame, iuv_lores, 0).rgb, 1));
		imageStore(uResultHistory, iuv, vec4(texelFetch(uHistoryFrame, iuv,       0).rgb, 1));
		imageStore(uDebug,  iuv, vec4(0));
		return;
	}
	if (ubo.mBypassHistoryUpdate) {
		imageStore(uResultScreen,  iuv, vec4(texelFetch(uHistoryFrame, iuv,       0).rgb, 1));	// FIXME - un-tonemap?; (low priority, only used for debugging anyway)
		imageStore(uResultHistory, iuv, vec4(texelFetch(uHistoryFrame, iuv,       0).rgb, 1));
		imageStore(uDebug,  iuv, vec4(0));
		return;
	}

	bool rejected  = false;
	bool rectified = false;
	vec3 rectified_diff;
	
	vec3 currentColor;
	vec3 colMin;
	vec3 colMax;
	vec3 colClipTowards;
	float beta;
	getColorAndAabb(iuv_lores, currentColor, colMin, colMax, colClipTowards);		// colors are in YCoGg (if enabled)
	// may have different unjitter settings than neighbourhood, so get current color separately
	if (ubo.mUpsampling) {
		currentColor = getCurrentUpsampledColor(iuv, uv, beta); 
	} else {
		currentColor = getCurrentColor(iuv_lores); 
		beta = 1.0;
	}
	float depth = texelFetch(uCurrentDepth, iuv_lores, 0).r;
	
//	vec4 clipSpace = vec4(uv * 2.0 - 1.0, depth, 1);
//	vec4 worldSpace = ubo.mInverseViewProjMatrix * clipSpace;
//	vec4 historyClipSpace = ubo.mHistoryViewProjMatrix * worldSpace;
//	vec2 historyUv = (historyClipSpace.xy / historyClipSpace.w) * 0.5 + 0.5;
//	float expectedHistoryDepth = historyClipSpace.z / historyClipSpace.w;
	vec2 historyUv;
	float expectedHistoryDepth;
	getHistoryPosition(uv, depth, historyUv, expectedHistoryDepth);
	
	vec3 historyColor = maybe_rgb_to_ycocg(sample_history_rgb(historyUv).rgb);

	float alpha = params.mAlpha;

	// ---- history rejection ----
	// reject out-of-texture history samples
	if (params.mRejectOutside) {
		if (any(lessThan(historyUv, vec2(0))) || any(greaterThanEqual(historyUv, vec2(1)))) {
			alpha = params.mRejectionAlpha;
			rejected = true;
		}
	}

	// cull by depth
	if (params.mDepthCulling) {
		// FIXME - shouldn't we better compare LINEAR depth?

		// problem with upsampling: cannot use texture() (can't lerp depth buffer), but historyUv is probably not a texel center; so: WHERE to sample uHistoryDepth (lores) ?
		float historyDepth = texelFetch(uHistoryDepth, uv_to_tc(historyUv, textureSize_loRes), 0).r;
		float depthEpsilon = 0.1 * (1.0 - historyDepth);
		if (abs(historyDepth - expectedHistoryDepth) > depthEpsilon) {
			alpha = params.mRejectionAlpha;
			rejected = true;
		}
	}

	// ---- history rectification ----
	vec3 origHistorColor = historyColor;

	// clip/clamp color
	switch (params.mColorClampingOrClipping) {
		case 1:
			historyColor = clamp(historyColor, colMin, colMax);
			break;
		case 2:
			historyColor = clipAabb(colMin, colMax, vec4(0,0,0,1), vec4(historyColor, 1.0)).rgb;
			break;
		case 3:
			//historyColor = clipAabbSlow(colMin, colMax, vec4(currentColor, 1.0), vec4(historyColor, 1.0)).rgb;	// this one has "fireflies" or "blackout"-problems with var clipping (even after fixing sigma-NaNs)
			//historyColor = clipAabbSlow(colMin, colMax, vec4(colAvg, 1.0), vec4(historyColor, 1.0)).rgb;			// not this... WHY NOT?	===> see getNeighbourhood, currentColor may NOT be inside AABB!
			historyColor = clipAabbSlow(colMin, colMax, vec4(colClipTowards, 1.0), vec4(historyColor, 1.0)).rgb;
			break;

	}

	rectified_diff = historyColor - origHistorColor;
	rectified = any(greaterThan(abs(rectified_diff), vec3(0.001)));


	// ---- blending ----

	if (!rejected) {
		// dynamic luma weighting - see Timothy Lottes https://www.youtube.com/watch?v=WzpLWzGvFK4&t=18m
		if (params.mLumaWeightingLottes) {
			float lumaCurrent = luminance(currentColor);
			float lumaHistory = luminance(historyColor);
			float diff = abs(lumaCurrent - lumaHistory) / max(max(lumaCurrent, lumaHistory), 0.2);
			float w = 1.0 - diff;
			float ww = w * w;
			// ww=0: bad history, use max alpha ; ww=1: good history, use min alpha
			alpha = mix(params.mMaxAlpha, params.mMinAlpha, ww);
		}

		// Anti-flicker: Reduce blend factor when history is near clamping [Karis14]
		if (params.mReduceBlendNearClamp) {
			// calculation adapted from NVidia's Falcor / Unreal Engine
			float colMin_lum  = luminance(colMin);
			float colMax_lum  = luminance(colMax);
			float history_lum = luminance(origHistorColor);
			#if 0
				// Falcor-based
				float distToClamp = min(abs(colMin_lum - history_lum), abs(colMax_lum - history_lum));
				float factor = distToClamp / (distToClamp + colMax_lum - colMin_lum);
				float alpha = clamp(alpha * factor, 0.0, 1.0);
				gDebugValue = vec4(factor, alpha, distToClamp, 0);
			#else
				// Unreal Engine-based (slightly modified)
				float distToClamp = 2.0 * abs(min(history_lum - colMin_lum, colMax_lum - history_lum)) / (colMax_lum - colMin_lum);	// what if max == min ?
				float alphaOrig = alpha;
				alpha += 0.8 * clamp(0.02 * history_lum / abs(luminance(currentColor) - history_lum), 0, 1);
				alpha = clamp(alpha, 0, 1);
				gDebugValue = vec4(alphaOrig, alpha, distToClamp, 0);
			#endif
		}
	}

	if (ubo.mResetHistory) { alpha = 1.0; beta = 1.0; }

	//vec3 antiAliased = mix(maybe_ycocg_to_rgb(historyColor), maybe_ycocg_to_rgb(currentColor), alpha * beta);	// current * ab + history * (1-ab)
	vec3 antiAliased = maybe_ycocg_to_rgb(mix(historyColor, currentColor, alpha * beta));	// current * ab + history * (1-ab)

	// add noise
	if (params.mAddNoise) {
		vec4 n = noise(uv);
		antiAliased += n.rgb;
	}

	vec3 output_to_history = antiAliased;
	vec3 output_to_screen  = un_tonemap_rgb(antiAliased);

	imageStore(uResultHistory, iuv, vec4(output_to_history, 1.0));
	imageStore(uResultScreen,  iuv, vec4(output_to_screen,  1.0));

	// --- debug ---

	if (params.mDebugMode == 0) {
		// colour bounding box, individual
		vec3 tmp = colMax - colMin;
		gDebugValue = vec4(tmp, 0);
	} else if (params.mDebugMode == 1) {
		// colour bounding box, size
		vec3 tmp = colMax - colMin;
		gDebugValue = vec4(vec3(tmp.x * tmp.y * tmp.z), 0);
	} else if (params.mDebugMode == 2) {
		gDebugValue = vec4(rejected ? 1 : 0, length(rectified_diff), 0, 0);
	} else if (params.mDebugMode == 3) {
		gDebugValue = vec4(vec3(alpha), 0);
	} else if (params.mDebugMode == 4) {
		gDebugValue = texelFetch(uCurrentVelocity, iuv, 0);
	} else if (params.mDebugMode == 5) {
		gDebugValue = vec4(output_to_screen, 0);
	} else if (params.mDebugMode == 6) {
		gDebugValue = vec4(output_to_history, 0);
	}
	// else keep current gDebugValue

	gDebugValue *= params.mDebugScale * params.mDebugMask;
	if (params.mDebugCenter) gDebugValue = gDebugValue * 0.5 + 0.5;
	imageStore(uDebug,  iuv, gDebugValue);

}
// -------------------------------------------------------

