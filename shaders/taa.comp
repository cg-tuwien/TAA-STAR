#version 460
#extension GL_EXT_samplerless_texture_functions : require
#extension GL_GOOGLE_include_directive : enable

#include "shader_cpu_common.h"

// TODO: recheck unjittering - jitter offsets are NDC! fixed now, test!

// ATTENTION:
// with upsampling enabled, the texture sizes are different now:
// lo-res: uCurrentFrame, uCurrentDepth, uCurrentVelocity, *uHistoryDepth*
// hi-res: uHistoryFrame, uResult, uDebug
//
// FIXME: decide res for uHistoryDepth (?)
// FIXME: hist depth sampling is problematic

// TODO upsampling:
// unjittering ?

// ###### SRC/DST IMAGES #################################
layout(set = 0, binding = 0) uniform sampler uSampler;
layout(set = 0, binding = 1) uniform texture2D uCurrentFrame;
layout(set = 0, binding = 2) uniform texture2D uCurrentDepth;
layout(set = 0, binding = 7) uniform texture2D uCurrentVelocity;
layout(set = 0, binding = 3) uniform texture2D uHistoryFrame;
layout(set = 0, binding = 4) uniform texture2D uHistoryDepth;
layout(set = 0, binding = 5, TAA_SHADER_OUTPUT_FORMAT) writeonly uniform restrict image2D uResult;
layout(set = 0, binding = 6, rgba16f) writeonly uniform restrict image2D uDebug;
// -------------------------------------------------------

// texelFetch is undefined when sampling outside the texture, so always clamp
#define CLAMP_TO_TEX(v) clamp((v), ivec2(0), textureSize(uCurrentFrame,0))

// shortcut to texture(sampler2D(texture, uSampler), uv)
#define SAMPLE_TEX(tex_,uv_) texture(sampler2D((tex_),uSampler), uv_)

#define JITTER_UV (params.mJitterNdcAndAlpha.xy * 0.5 * params.mUnjitterFactor)

// ###### PUSH CONSTANTS AND UBOs ########################
struct Parameters {
	vec4 mJitterNdcAndAlpha;		// jitter is in NDC units, NOT UV units!
	int  mColorClampingOrClipping;
	bool mDepthCulling;
	//bool mTextureLookupUnjitter;
	bool mUnjitterNeighbourhood;
	bool mUnjitterCurrentSample;	// TODO: anything for depth/history depth??
	float mUnjitterFactor;			// -1 or +1, for debugging

	bool mBypassHistoryUpdate;
	bool mPassThrough;				// effectively disables TAA: history <- input, result <- input,
	bool mUseYCoCg;
	bool mVarianceClipping;
	bool mShapedNeighbourhood;
	bool mLumaWeighting;
	float mVarClipGamma;
	float mMinAlpha;				// used for luminance-based weighting
	float mMaxAlpha;				// used for luminance-based weighting
	float mRejectionAlpha;
	bool mRejectOutside;
	int mUseVelocityVectors;		// 0=off 1=for movers only 2=for everything
	bool mUseLongestVelocityVector;
	int mInterpolationMode;			// 0=bilinear 1=bicubic b-spline 2=bicubic catmull-rom

	int  mDebugMode;
	float mDebugScale;
	bool mDebugCenter;

	float pad1, pad2;
};
layout(push_constant) uniform PushConstants {
	Parameters	param[2];
	bool		splitScreen;
	int			splitX;
	bool        mUpsampling;
} pushConstants;

Parameters params;

layout(set = 1, binding = 0) uniform Matrices {
	mat4 mHistoryViewProjMatrix;
	mat4 mInverseViewProjMatrix;
} uboMat;
// -------------------------------------------------------

// Globals
ivec2 textureSize_loRes;
ivec2 textureSize_hiRes;

// Just for debugging:
vec4 gDebugValue = vec4(0);

// ###### HELPER FUNCTIONS ###############################

// texel coords <-> uv conversion
vec2  tc_to_uv(ivec2 tc, ivec2 texSize) { return (vec2(tc) + 0.5) / texSize; }
ivec2 uv_to_tc(vec2 uv,  ivec2 texSize) { return ivec2(uv * texSize); }

ivec2 hiRes_to_loRes_Tc(ivec2 hires_tc) {
	return uv_to_tc(tc_to_uv(hires_tc, textureSize_hiRes), textureSize_loRes);
}


//// convert from RGB to YCoCg-R ; see https://en.wikipedia.org/wiki/YCoCg
//vec3 rgb_to_ycocg(vec3 c) {
//	float co  = c.r - c.b;
//	float tmp = c.b + co * .5;
//	float cg  = c.g - tmp;
//	float y   = tmp + cg * .5;
//	return vec3(y,co,cg);
//}
//
//// convert from YCoCg-R to RGB
//vec3 ycocg_to_rgb(vec3 c) {
//	float tmp = c.x - c.z * .5;
//	float g   = c.z + tmp;
//	float b   = tmp - c.y * .5;
//	float r   = b + c.y;
//	return vec3(r,g,b);
//}

// convert from RGB to YCoCg ; see https://en.wikipedia.org/wiki/YCoCg
vec3 rgb_to_ycocg(vec3 c) {
	return vec3(
		 .25 * c.r + .5 * c.g + .25 * c.b,
		 .5  * c.r            - .5  * c.b,
		-.25 * c.r + .5 * c.g - .25 * c.b
	);
}

// convert from YCoCg to RGB
vec3 ycocg_to_rgb(vec3 c) {
	float tmp = c.x - c.z;	// tmp = Y   - Cg;
	return vec3(
		tmp + c.y,	// R   = tmp + Co;
		c.x + c.z,	// G   = Y   + Cg;
		tmp - c.y	// B   = tmp - Co;
	);
}


vec3 maybe_rgb_to_ycocg(vec3 c) { return params.mUseYCoCg ? rgb_to_ycocg(c) : c; }
vec3 maybe_ycocg_to_rgb(vec3 c) { return params.mUseYCoCg ? ycocg_to_rgb(c) : c; }
float luminance(vec3 c) { return params.mUseYCoCg ? c.x : rgb_to_ycocg(c).x; }

void getNeighbourhood(in ivec2 iuv, out vec3 cC, out vec3 c1, out vec3 c2, out vec3 c3, out vec3 c4, out vec3 c5, out vec3 c6, out vec3 c7, out vec3 c8) {
	vec2 offset = params.mUnjitterNeighbourhood ? JITTER_UV : vec2(0);

	vec2 invsize = vec2(1) / textureSize(uCurrentFrame, 0);

	cC = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv                 + 0.5) * invsize).rgb);
	c1 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2(-1, -1) + 0.5) * invsize).rgb);
	c2 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 0, -1) + 0.5) * invsize).rgb);
	c3 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 1, -1) + 0.5) * invsize).rgb);
	c4 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2(-1,  0) + 0.5) * invsize).rgb);
	c5 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 1,  0) + 0.5) * invsize).rgb);
	c6 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2(-1,  1) + 0.5) * invsize).rgb);
	c7 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 0,  1) + 0.5) * invsize).rgb);
	c8 = maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + ivec2( 1,  1) + 0.5) * invsize).rgb);
}

// may have different unjitter settings than getNeighbourhood
vec3 getCurrentColor(in ivec2 iuv) {
	vec2 offset = params.mUnjitterCurrentSample ? JITTER_UV : vec2(0);
	vec2 invsize = vec2(1) / textureSize(uCurrentFrame, 0);
	return maybe_rgb_to_ycocg(texture(sampler2D(uCurrentFrame, uSampler), offset + vec2(iuv + 0.5) * invsize).rgb);
}

vec3 getCurrentUpsampledColor(in ivec2 currentTc, in vec2 currentUv, out float beta) {
	// non-upsampling behaviour was:
	//beta = 1.0; return getCurrentColor(hiRes_to_loRes_Tc(currentTc));

	// only consider input samples that fall into the current texel after upscaling

	// example: hi-res = 2 x lores, consider input at center of texels 100, 101 -> = tc 100.5 (with non-normalized texture-coords tc); jitter is in texel units
	// jitter 0   : input 100.50 -> output 201.0 (203.0)
	// jitter -.25: input 100.25 -> output 200.5 (202.5)
	// jitter +.25: input 100.75 -> output 201.5 (203.5)
	// jitter -.40: input 100.10 -> output 200.2 (202.2), so update output tc [200-201) and [202-203), but not [201-202)
	// jitter J   : input I+J    -> output scale * (I + J)
	// O = s * (I + J) -> O/s - J = I

	vec2 scale = vec2(textureSize_hiRes) / vec2(textureSize_loRes);

	vec2 texelJitter = JITTER_UV * textureSize_loRes * -1;	// * -1 works... but WHY subtract jitter instead of adding?
	vec2 inTcSample;
	vec2 foundTc = vec2(-1,-1);
	const float almostOne = 0.999999;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(0,        0        )) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(almostOne,0        )) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(0,        almostOne)) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;
	inTcSample = floor(textureSize_loRes * vec2(currentTc + vec2(almostOne,almostOne)) / textureSize_hiRes) + 0.5 + texelJitter; if (ivec2(inTcSample * scale) == currentTc) foundTc = inTcSample;

	gDebugValue = foundTc.x >= 0.0 ? vec4(1, foundTc, 0) : vec4(0);	

	if (foundTc.x >= 0.0) {
		beta = 1.0;
		vec2 texUv = (floor(foundTc) + 0.5) / textureSize_loRes;
		return maybe_rgb_to_ycocg(SAMPLE_TEX(uCurrentFrame, texUv).rgb);
	} else {
		beta = 0.0;
		return vec3(0);
	}
}

void getColorAndAabb(in ivec2 iuv, out vec3 centerCol, out vec3 minCol, out vec3 maxCol, out vec3 cliptowardsCol)
{
	const float N = 9.0; // number of samples
	vec3 c1,c2,c3,c4,c5,c6,c7,c8;
	getNeighbourhood(iuv, centerCol,c1,c2,c3,c4,c5,c6,c7,c8);

	// variance clipping?
	if (params.mVarianceClipping) {
		vec3 m1 = centerCol + c1 + c2 + c3 + c4 + c5 + c6 + c7 + c8;
		vec3 m2 = centerCol*centerCol + c1*c1 + c2*c2 + c3*c3 + c4*c4 + c5*c5 + c6*c6 + c7*c7 + c8*c8;
		vec3 mean = m1 / N;
		vec3 sigma = sqrt(max(vec3(0), m2 / N - mean * mean));	// !! Here be dragons! (due to precision? - without the max(), some sigma components can get NaN!)
		minCol = mean - params.mVarClipGamma * sigma;
		maxCol = mean + params.mVarClipGamma * sigma;

		// NOTE: it is NOT guaranteed that centerCol is inside the AABB !
		// so clip towards the mean
		cliptowardsCol = mean;

		// TODO: we can even clip the other AABB against this one
	} else if (params.mShapedNeighbourhood) {
		vec3 minCol_3x3  = min(min(min(min(min(min(min(min(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		vec3 maxCol_3x3  = max(max(max(max(max(max(max(max(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		vec3 minCol_5tap = min(min(min(min(centerCol, c2), c4), c5), c7);
		vec3 maxCol_5tap = max(max(max(max(centerCol, c2), c4), c5), c7);
		minCol = (minCol_3x3 + minCol_5tap) * 0.5;
		maxCol = (maxCol_3x3 + maxCol_5tap) * 0.5;
		cliptowardsCol = centerCol;

	} else {
		minCol = min(min(min(min(min(min(min(min(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		maxCol = max(max(max(max(max(max(max(max(centerCol, c1), c2), c3), c4), c5), c6), c7), c8);
		cliptowardsCol = centerCol; // here centerCol is always inside the AABB; note: playdead still clip towards average color 
	}

	// TODO: optionally unjitter differently: neighbourhood samples, current color -> need to make sure cliptowardsCol stays inside AABB

	//if (any(lessThan(centerCol, minCol)) || any(greaterThan(centerCol, maxCol))) gDebugValue = vec4(1,0,0,0);
}

// Code from Temporal Reprojection Anti-Aliasing in INSIDE: https://youtu.be/2XXS5UyNjjU?t=939
// note: clips towards aabb center + p.w
vec4 clipAabb(
	vec3 aabbMin, // cn_min
	vec3 aabbMax, // cn_max
	vec4 p,       // c_in'		// only p.w is used (and typically is 1)
	vec4 q)       // c_hist
{
	const float eps = 1e-7;

	vec3 pClip = 0.5 * (aabbMax + aabbMin);
	vec3 eClip = 0.5 * (aabbMax - aabbMin) + eps; // ac: added epsilon

	vec4 vClip = q - vec4(pClip, p.w);
	vec3 vUnit = vClip.xyz / eClip;
	vec3 aUnit = abs(vUnit);
	float maUnit = max(aUnit.x, max(aUnit.y, aUnit.z));

	if (maUnit > 1.0) {
		return vec4(pClip, p.w) + vClip / maUnit;
	}
	else {
		return q; // point inside aabb
	}
}

// slow clipping, but not only towards centre; code from playdead -- DOES NOT WORK PROPERLY!
vec4 clipAabbSlow(
	vec3 aabbMin, // cn_min
	vec3 aabbMax, // cn_max
	vec4 p,       // c_in'
	vec4 q)       // c_hist
{
		vec4 r = q - p;
		vec3 rmax = aabbMax - p.xyz;
		vec3 rmin = aabbMin - p.xyz;

		const float eps = 1e-7;

		// !! BEWARE !! divs by zero happen here !!
		if (r.x > rmax.x + eps) r *= (rmax.x / r.x);
		if (r.y > rmax.y + eps) r *= (rmax.y / r.y);
		if (r.z > rmax.z + eps) r *= (rmax.z / r.z);
		if (r.x < rmin.x - eps) r *= (rmin.x / r.x);
		if (r.y < rmin.y - eps) r *= (rmin.y / r.y);
		if (r.z < rmin.z - eps) r *= (rmin.z / r.z);

		return p + r;
}

#if TAA_OUTPUT_IS_SRGB
float srgbGammaCorr(float color)
{
	if (color <= 0.0031308)
		return 12.92 * color;

	float a = 0.055;
	return (1 + a) * pow(color, 1 / 2.4) - a;
}

vec3 rgb2srgb(vec3 rgb)
{
	vec3 srgb;
	srgb.r = srgbGammaCorr(rgb.r);
	srgb.g = srgbGammaCorr(rgb.g);
	srgb.b = srgbGammaCorr(rgb.b);
	return srgb;
}

#define TO_OUTPUT_FORMAT(x) rgb2srgb((x))
#else
#define TO_OUTPUT_FORMAT(x) (x)
#endif

void getHistoryPosition(in vec2 currentUv, in float currentDepth, out vec2 historyUv, out float historyDepth) {
	vec4 velocitySample = SAMPLE_TEX(uCurrentVelocity, currentUv);

	bool canUseVelocity = true;
	if (params.mUseVelocityVectors == 0 || (params.mUseVelocityVectors == 1 && velocitySample.w < 0.5)) canUseVelocity = false;

	if (canUseVelocity) {
		if (params.mUseLongestVelocityVector) {
			// sample 3x3 neighbourhood, take longest vector ; note: we don't deal with depth here, should we?
			vec2 toUv = vec2(1,1) / textureSize(uCurrentVelocity, 0);
			vec2 maxVel = velocitySample.xy;
			vec2 sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 1, -1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2(-1,  0)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2(-1, -1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 0, -1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2(-1,  1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 0,  1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 1,  0)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			sam = SAMPLE_TEX(uCurrentVelocity, currentUv + toUv * vec2( 1,  1)).xy; if (dot(sam,sam) > dot(maxVel,maxVel)) maxVel = sam;
			velocitySample.xy = sam;
		}

		// velocity sample is already scaled from ndc to uv in .xy, .z holds the raw (ndc) depth difference
		historyUv    = currentUv    - velocitySample.xy;
		historyDepth = currentDepth - velocitySample.z;
		// TODO: check if material history is same object and set canUseVelocity = false otherwise
	}

	if (!canUseVelocity) {
		vec4 clipSpace = vec4(currentUv * 2.0 - 1.0, currentDepth, 1);
		vec4 worldSpace = uboMat.mInverseViewProjMatrix * clipSpace;
		vec4 historyClipSpace = uboMat.mHistoryViewProjMatrix * worldSpace;
		historyUv = (historyClipSpace.xy / historyClipSpace.w) * 0.5 + 0.5;
		historyDepth = historyClipSpace.z / historyClipSpace.w;
	}

	// TODO: need to adjust for current jitter if history buf is considered unjittered?
}

// see https://vec3.ca/bicubic-filtering-in-fewer-taps/
vec4 sample_history_bicubic_catmullrom(vec2 uv) {
	vec2 texSize = textureSize(uHistoryFrame, 0);
	vec2 invTexSize = 1.0 / texSize;

	vec2 iTc = uv * texSize;
	vec2 tc = floor(iTc - 0.5) + 0.5;	// round *down* to nearest texel center
	vec2 f = iTc - tc;
	vec2 f2 = f * f;
	vec2 f3 = f2 * f;

	// Calculate weights:
	//                   9|d|^3 - 15|d|^2         +  6   for 0 <= |d| <= 1
	// w(d) = (1/6) * { -3|d|^3 + 15|d|^2 - 24|d| + 12   for 1 <  |d| <= 2
	//                   0                               otherwise
	//
	// |d0|=f+1   |d1|=f   |d2|=1-f   |d3|=2-f
	//
	// expands to:
	//  w0 = (-3 * f^3 +  6 * f^2 - 3 * f     ) / 6
	//  w1 = ( 9 * f^3 - 15 * f^2         + 6 ) / 6	      ! there is a typo in the linked article! coefficient for f^3 is 9, not 6 !
	//  w2 = (-9 * f^3 + 12 * f^2 + 3 * f     ) / 6
	//  w3 = ( 3 * f^3 -  3 * f^2             ) / 6

	vec2 w0 = -0.5 * f3 +        f2 - 0.5 * f       ;
	vec2 w1 =  1.5 * f3 -  2.5 * f2           + 1.0 ;
	vec2 w2 = -1.5 * f3 +  2.0 * f2 + 0.5 * f       ;
	vec2 w3 =  0.5 * f3 -  0.5 * f2                 ;

	#if 0
		// naive implementation, slow (16 taps!), just for comparison

		// Note: there is *no* linear interpolation going on, we sample the texture at exact texel centers.
		//       Works equally well with texture() or texelFetch() (which needs manual clamping)
		//       Tests showed the texelFetch-variant is minusculely faster, but the difference is barely noticeable 
		ivec2 tc0 = clamp(ivec2(tc - 1), ivec2(0), ivec2(texSize));
		ivec2 tc1 = clamp(ivec2(tc 	  ), ivec2(0), ivec2(texSize));
		ivec2 tc2 = clamp(ivec2(tc + 1), ivec2(0), ivec2(texSize));
		ivec2 tc3 = clamp(ivec2(tc + 2), ivec2(0), ivec2(texSize));
		return
		  texelFetch(uHistoryFrame, ivec2(tc0.x, tc0.y), 0) * w0.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc0.y), 0) * w1.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc0.y), 0) * w2.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc0.y), 0) * w3.x * w0.y
		+ texelFetch(uHistoryFrame, ivec2(tc0.x, tc1.y), 0) * w0.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc1.y), 0) * w1.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc1.y), 0) * w2.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc1.y), 0) * w3.x * w1.y
		+ texelFetch(uHistoryFrame, ivec2(tc0.x, tc2.y), 0) * w0.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc2.y), 0) * w1.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc2.y), 0) * w2.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc2.y), 0) * w3.x * w2.y
		+ texelFetch(uHistoryFrame, ivec2(tc0.x, tc3.y), 0) * w0.x * w3.y
		+ texelFetch(uHistoryFrame, ivec2(tc1.x, tc3.y), 0) * w1.x * w3.y
		+ texelFetch(uHistoryFrame, ivec2(tc2.x, tc3.y), 0) * w2.x * w3.y
		+ texelFetch(uHistoryFrame, ivec2(tc3.x, tc3.y), 0) * w3.x * w3.y;
	#else
		// optimized version, 9 taps only
		// Note: this exploits bilinear filtering, so no texelFetch'ing here!
		vec2 wC = w1 + w2;
		vec2 tc0 = (tc - 1    ) * invTexSize;
		vec2 tcC = (tc + w2/wC) * invTexSize;
		vec2 tc3 = (tc + 2    ) * invTexSize;
		return
		  SAMPLE_TEX(uHistoryFrame, vec2(tc0.x, tc0.y)) * w0.x * w0.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tcC.x, tc0.y)) * wC.x * w0.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc3.x, tc0.y)) * w3.x * w0.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc0.x, tcC.y)) * w0.x * wC.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tcC.x, tcC.y)) * wC.x * wC.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc3.x, tcC.y)) * w3.x * wC.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc0.x, tc3.y)) * w0.x * w3.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tcC.x, tc3.y)) * wC.x * w3.y
		+ SAMPLE_TEX(uHistoryFrame, vec2(tc3.x, tc3.y)) * w3.x * w3.y;
	#endif
}

// see https://vec3.ca/bicubic-filtering-in-fewer-taps/
vec4 sample_history_bicubic_b_spline(vec2 uv) {
	vec2 texSize = textureSize(uHistoryFrame, 0);
	vec2 invTexSize = 1.0 / texSize;

	vec2 iTc = uv * texSize;
	vec2 tc = floor(iTc - 0.5) + 0.5;	// round *down* to nearest texel center
	vec2 f = iTc - tc;
	vec2 f2 = f * f;
	vec2 f3 = f2 * f;

	vec2 w0 = f2 - 0.5 * (f3 + f);
	vec2 w1 = 1.5 * f3 - 2.5 * f2 + 1.0;
	vec2 w3 = 0.5 * (f3 - f2);
	vec2 w2 = 1.0 - w0 - w1 - w3;

	vec2 s0 = w0 + w1;
	vec2 s1 = w2 + w3;
	vec2 f0 = w1 / (w0 + w1);
	vec2 f1 = w3 / (w2 + w3);
	vec2 t0 = (tc - 1 + f0) * invTexSize;
	vec2 t1 = (tc + 1 + f1) * invTexSize;

	return (SAMPLE_TEX(uHistoryFrame, vec2(t0.x, t0.y)) * s0.x
	     +  SAMPLE_TEX(uHistoryFrame, vec2(t1.x, t0.y)) * s1.x) * s0.y
	     + (SAMPLE_TEX(uHistoryFrame, vec2(t0.x, t1.y)) * s0.x
	     +  SAMPLE_TEX(uHistoryFrame, vec2(t1.x, t1.y)) * s1.x) * s1.y;
}

vec4 sample_history_rgb(vec2 uv) {
	if      (params.mInterpolationMode == 0)	return SAMPLE_TEX(uHistoryFrame, uv);
	else if (params.mInterpolationMode == 1)	return sample_history_bicubic_b_spline(uv);
	else										return sample_history_bicubic_catmullrom(uv);
}

// -------------------------------------------------------

// ################## COMPUTE SHADER MAIN ###################
layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;
void main()
{
	textureSize_hiRes = textureSize(uHistoryFrame, 0);
	textureSize_loRes = textureSize(uCurrentFrame, 0);

	ivec2 iuv = ivec2(gl_GlobalInvocationID.xy);
	vec2 uv = tc_to_uv(iuv, textureSize_hiRes);
	if (any(greaterThanEqual(iuv, textureSize_hiRes))) return;

	int paramsIdx = (pushConstants.splitScreen && iuv.x > pushConstants.splitX) ? 1 : 0;
	params = pushConstants.param[paramsIdx];


	ivec2 iuv_lores = uv_to_tc(uv, textureSize_loRes);

	if (params.mPassThrough) {
		imageStore(uResult, iuv, vec4(TO_OUTPUT_FORMAT(texelFetch(uCurrentFrame, iuv_lores, 0).rgb), 1));
		imageStore(uDebug,  iuv, vec4(0));
		return;
	}
	if (params.mBypassHistoryUpdate) {
		imageStore(uResult, iuv, vec4(TO_OUTPUT_FORMAT(texelFetch(uHistoryFrame, iuv, 0).rgb), 1));
		imageStore(uDebug,  iuv, vec4(0));
		return;
	}

	bool rejected  = false;
	bool rectified = false;
	vec3 rectified_diff;
	
	vec3 currentColor;
	vec3 colMin;
	vec3 colMax;
	vec3 colClipTowards;
	float beta;
	getColorAndAabb(iuv_lores, currentColor, colMin, colMax, colClipTowards);		// colors are in YCoGg (if enabled)
	// may have different unjitter settings than neighbourhood, so get current color separately
	if (pushConstants.mUpsampling) {
		currentColor = getCurrentUpsampledColor(iuv, uv, beta); 
	} else {
		currentColor = getCurrentColor(iuv_lores); 
		beta = 1.0;
	}
	float depth = texelFetch(uCurrentDepth, iuv_lores, 0).r;
	
//	vec4 clipSpace = vec4(uv * 2.0 - 1.0, depth, 1);
//	vec4 worldSpace = uboMat.mInverseViewProjMatrix * clipSpace;
//	vec4 historyClipSpace = uboMat.mHistoryViewProjMatrix * worldSpace;
//	vec2 historyUv = (historyClipSpace.xy / historyClipSpace.w) * 0.5 + 0.5;
//	float expectedHistoryDepth = historyClipSpace.z / historyClipSpace.w;
	vec2 historyUv;
	float expectedHistoryDepth;
	getHistoryPosition(uv, depth, historyUv, expectedHistoryDepth);
	
	vec3 historyColor = maybe_rgb_to_ycocg(sample_history_rgb(historyUv).rgb);

	float alpha = params.mJitterNdcAndAlpha.a;

	// ---- history rejection ----
	// reject out-of-texture history samples
	if (params.mRejectOutside) {
		if (any(lessThan(historyUv, vec2(0))) || any(greaterThanEqual(historyUv, vec2(1)))) {
			alpha = params.mRejectionAlpha;
			rejected = true;
		}
	}

	// cull by depth
	if (params.mDepthCulling) {
		// FIXME - shouldn't we better compare LINEAR depth?

		// problem with upsampling: cannot use texture() (can't lerp depth buffer), but historyUv is probably not a texel center; so: WHERE to sample uHistoryDepth (lores) ?
		float historyDepth = texelFetch(uHistoryDepth, uv_to_tc(historyUv, textureSize_loRes), 0).r;
		float depthEpsilon = 0.1 * (1.0 - historyDepth);
		if (abs(historyDepth - expectedHistoryDepth) > depthEpsilon) {
			alpha = params.mRejectionAlpha;
			rejected = true;
		}
	}

	// ---- history rectification ----
	vec3 origHistorColor = historyColor;

	// clip/clamp color
	switch (params.mColorClampingOrClipping) {
		case 1:
			historyColor = clamp(historyColor, colMin, colMax);
			break;
		case 2:
			//historyColor = clipAabb(colMin, colMax, vec4(currentColor, 1.0), vec4(historyColor, 1.0)).rgb;
			// TODO: Implemented ^ this in a hurry => not properly tested and verified yet.
			historyColor = clipAabb(colMin, colMax, vec4(0,0,0,1), vec4(historyColor, 1.0)).rgb;
			break;
		case 3:
			//historyColor = clipAabbSlow(colMin, colMax, vec4(currentColor, 1.0), vec4(historyColor, 1.0)).rgb;	// this one has "fireflies" or "blackout"-problems with var clipping (even after fixing sigma-NaNs)
			//historyColor = clipAabbSlow(colMin, colMax, vec4(colAvg, 1.0), vec4(historyColor, 1.0)).rgb;			// not this... WHY NOT?	===> see getNeighbourhood, currentColor may NOT be inside AABB!
			historyColor = clipAabbSlow(colMin, colMax, vec4(colClipTowards, 1.0), vec4(historyColor, 1.0)).rgb;
			break;

	}

	rectified_diff = historyColor - origHistorColor;
	rectified = any(greaterThan(abs(rectified_diff), vec3(0.001)));


	// ---- blending ----

	if (!rejected) {
		// dynamic luma weighting - see Timothy Lottes https://www.youtube.com/watch?v=WzpLWzGvFK4&t=18m
		if (params.mLumaWeighting) {
			float lumaCurrent = luminance(currentColor);
			float lumaHistory = luminance(historyColor);
			float diff = abs(lumaCurrent - lumaHistory) / max(max(lumaCurrent, lumaHistory), 0.2);
			float w = 1.0 - diff;
			float ww = w * w;
			// ww=0: bad history, use max alpha ; ww=1: good history, use min alpha
			alpha = mix(params.mMaxAlpha, params.mMinAlpha, ww);
		}
	}

	//vec3 antiAliased = mix(maybe_ycocg_to_rgb(historyColor), maybe_ycocg_to_rgb(currentColor), alpha * beta);	// current * ab + history * (1-ab)
	vec3 antiAliased = maybe_ycocg_to_rgb(mix(historyColor, currentColor, alpha * beta));	// current * ab + history * (1-ab)

	// if TAA_OUTPUT_IS_SRGB:
	// write rgb into uResult
	// - imageStore() cannot handle sRGB images
	// - we write sRGB values into an RGB image and copy the image into an sRGB image later as a workaround
	// => we have to manually convert linear RGB to sRGB

	imageStore(uResult, iuv, vec4(TO_OUTPUT_FORMAT(antiAliased), 1.0));

	// --- debug ---

	if (params.mDebugMode == 0) {
		// colour bounding box, individual
		vec3 tmp = colMax - colMin;
		gDebugValue = vec4(tmp, 0);
	} else if (params.mDebugMode == 1) {
		// colour bounding box, size
		vec3 tmp = colMax - colMin;
		gDebugValue = vec4(vec3(tmp.x * tmp.y * tmp.z), 0);
	} else if (params.mDebugMode == 2) {
		//imageStore(uDebug,  iuv, vec4(rejected ? 1 : 0, rectified ? 1 : 0, 0, 0));
		gDebugValue = vec4(rejected ? 1 : 0, length(rectified_diff), 0, 0);
	} else if (params.mDebugMode == 3) {
		gDebugValue = vec4(vec3(alpha), 0);
	} else if (params.mDebugMode == 4) {
		gDebugValue = texelFetch(uCurrentVelocity, iuv, 0);
	} else if (params.mDebugMode == 5) {
		gDebugValue = vec4(antiAliased, 0);
	}
	// else keep current gDebugValue

	gDebugValue *= params.mDebugScale;
	if (params.mDebugCenter) gDebugValue = gDebugValue * 0.5 + 0.5;
	imageStore(uDebug,  iuv, gDebugValue);

}
// -------------------------------------------------------

